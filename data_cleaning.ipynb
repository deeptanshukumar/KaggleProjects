{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuR0wQmyou2j"
      },
      "source": [
        "# Part 1: Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uzF5kL5AogPh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZRjrRPLpIBI"
      },
      "source": [
        "# Part 2: Handling Missing Values\n",
        "# We'll demonstrate handling missing values by imputing them with the mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kVAxwdPspLhF"
      },
      "outputs": [],
      "source": [
        "# Create a sample DataFrame with missing values\n",
        "data = {'A': [1, 2, np.nan, 4], 'B': [np.nan, 2, 3, 4]}\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Uzvp35pYYP",
        "outputId": "978710f8-d84d-423e-8447-c39067bdca53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original DataFrame with Missing Values:\n",
            "     A    B\n",
            "0  1.0  NaN\n",
            "1  2.0  2.0\n",
            "2  NaN  3.0\n",
            "3  4.0  4.0\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame with missing values\n",
        "print(\"Original DataFrame with Missing Values:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MOxGyx__pbHj"
      },
      "outputs": [],
      "source": [
        "# Impute missing values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv26ZM17pdaF",
        "outputId": "bd791050-2592-4518-caba-5a53f2295c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after Imputation (Missing Values Filled):\n",
            "          A    B\n",
            "0  1.000000  3.0\n",
            "1  2.000000  2.0\n",
            "2  2.333333  3.0\n",
            "3  4.000000  4.0\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame after imputation\n",
        "print(\"\\nDataFrame after Imputation (Missing Values Filled):\")\n",
        "print(df_imputed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k88RirkLpgua"
      },
      "source": [
        "# Part 3: Removing Duplicate Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V6827plWpjSi"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame with duplicate rows\n",
        "data_with_duplicates = {'Name': ['Alice', 'Bob', 'Alice', 'Charlie'],\n",
        "                        'Age': [25, 30, 25, 35]}\n",
        "df_duplicates = pd.DataFrame(data_with_duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui73m8NoplnK",
        "outputId": "5588c566-7ea8-422c-dd9e-5826f8d7e9c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original DataFrame with Duplicates:\n",
            "      Name  Age\n",
            "0    Alice   25\n",
            "1      Bob   30\n",
            "2    Alice   25\n",
            "3  Charlie   35\n"
          ]
        }
      ],
      "source": [
        "# Display the original DataFrame with duplicates\n",
        "print(\"\\nOriginal DataFrame with Duplicates:\")\n",
        "print(df_duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cPVjvayCpoKC"
      },
      "outputs": [],
      "source": [
        "# Removing duplicates based on the 'Name' column\n",
        "df_no_duplicates = df_duplicates.drop_duplicates(subset='Name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upCwqg6Tp7hb",
        "outputId": "829bd3a2-2e47-4caa-d02a-6bae7e101af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After Removing Duplicates:\n",
            "      Name  Age\n",
            "0    Alice   25\n",
            "1      Bob   30\n",
            "3  Charlie   35\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame after removing duplicates\n",
        "print(\"\\nDataFrame After Removing Duplicates:\")\n",
        "print(df_no_duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkz31nmvp9uh"
      },
      "source": [
        "# Part 4: Converting Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iU5bmWDhqBCj"
      },
      "outputs": [],
      "source": [
        "# Sample DataFrame with date strings\n",
        "data_with_dates = {'Date': ['2020-01-01', '2020-02-01', '2020-03-01']}\n",
        "df_dates = pd.DataFrame(data_with_dates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY8pRHV1qDCZ",
        "outputId": "44ae574f-d82f-48f4-80dd-f455e4fb30f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original DataFrame with Date Strings:\n",
            "         Date\n",
            "0  2020-01-01\n",
            "1  2020-02-01\n",
            "2  2020-03-01\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame with dates as strings\n",
        "print(\"\\nOriginal DataFrame with Date Strings:\")\n",
        "print(df_dates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oSmE0RE-qF2M"
      },
      "outputs": [],
      "source": [
        "# Converting the 'Date' column from string to datetime\n",
        "df_dates['Date'] = pd.to_datetime(df_dates['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxbJ41peqH9L",
        "outputId": "11954cb3-0592-4fe5-92ef-a9c7fb4e84c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After Converting to Datetime:\n",
            "        Date\n",
            "0 2020-01-01\n",
            "1 2020-02-01\n",
            "2 2020-03-01\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame after conversion\n",
        "print(\"\\nDataFrame After Converting to Datetime:\")\n",
        "print(df_dates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyozEyZqLAW"
      },
      "source": [
        "# Part 5: Handling Outliers Using IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zUMr-55mqOHz"
      },
      "outputs": [],
      "source": [
        "# Sample DataFrame with outliers\n",
        "data_with_outliers = {'Score': [50, 60, 70, 80, 200]}\n",
        "df_outliers = pd.DataFrame(data_with_outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t-CEdfszqRCt"
      },
      "outputs": [],
      "source": [
        "# Calculate the IQR (Interquartile Range)\n",
        "Q1 = df_outliers['Score'].quantile(0.25)\n",
        "Q3 = df_outliers['Score'].quantile(0.75)\n",
        "IQR = Q3 - Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AgPdIlTnqTY0"
      },
      "outputs": [],
      "source": [
        "# Removing outliers beyond 1.5 * IQR\n",
        "df_no_outliers = df_outliers[(df_outliers['Score'] >= (Q1 - 1.5 * IQR)) &\n",
        "                              (df_outliers['Score'] <= (Q3 + 1.5 * IQR))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RrAJZPqqVhz",
        "outputId": "80ae7429-58b8-4795-8266-6a63d1ce3198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After Removing Outliers (IQR-based):\n",
            "   Score\n",
            "0     50\n",
            "1     60\n",
            "2     70\n",
            "3     80\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame after removing outliers\n",
        "print(\"\\nDataFrame After Removing Outliers (IQR-based):\")\n",
        "print(df_no_outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbYRT5S3qZlh"
      },
      "source": [
        "# Part 6: One-Hot Encoding Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nEUuznVsqX8r"
      },
      "outputs": [],
      "source": [
        "# Sample DataFrame with categorical data\n",
        "data_with_categories = {'Category': ['A', 'B', 'A', 'C', 'B']}\n",
        "df_categories = pd.DataFrame(data_with_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqq3zfTdqfLO"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the 'Category' column\n",
        "df_encoded = pd.get_dummies(df_categories, columns=['Category']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14i7jbqCqhlV",
        "outputId": "81e04c33-6c01-4da0-8a57-73b309381d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After One-Hot Encoding:\n",
            "   Category_A  Category_B  Category_C\n",
            "0        True       False       False\n",
            "1       False        True       False\n",
            "2        True       False       False\n",
            "3       False       False        True\n",
            "4       False        True       False\n"
          ]
        }
      ],
      "source": [
        "# Display the DataFrame after encoding\n",
        "print(\"\\nDataFrame After One-Hot Encoding:\")\n",
        "print(df_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdpKsxA0qjZ2"
      },
      "source": [
        "# Part 7: Normalizing and Standardizing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KUiN266QqmWR"
      },
      "outputs": [],
      "source": [
        "# Sample DataFrame with features to scale\n",
        "data_to_scale = {'Feature1': [10, 20, 30, 40, 50], 'Feature2': [100, 200, 300, 400, 500]}\n",
        "df_scale = pd.DataFrame(data_to_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "61znyC0zqw7J"
      },
      "outputs": [],
      "source": [
        "# Normalizing the data using Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "df_normalized = pd.DataFrame(scaler.fit_transform(df_scale), columns=df_scale.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzv9ksenqzKE",
        "outputId": "05309fc6-3f08-4bed-a94d-e964ee96b4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After Normalization (Min-Max Scaling):\n",
            "   Feature1  Feature2\n",
            "0      0.00      0.00\n",
            "1      0.25      0.25\n",
            "2      0.50      0.50\n",
            "3      0.75      0.75\n",
            "4      1.00      1.00\n"
          ]
        }
      ],
      "source": [
        "# Display the normalized DataFrame\n",
        "print(\"\\nDataFrame After Normalization (Min-Max Scaling):\")\n",
        "print(df_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g9ABx7Pfq2dp"
      },
      "outputs": [],
      "source": [
        "# Standardizing the data using Z-score Scaling\n",
        "scaler_standard = StandardScaler()\n",
        "df_standardized = pd.DataFrame(scaler_standard.fit_transform(df_scale), columns=df_scale.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLkDJqXoq41P",
        "outputId": "ed1b5bfb-27ef-43e7-c5ee-f2da910e1ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After Standardization (Z-score Scaling):\n",
            "   Feature1  Feature2\n",
            "0 -1.414214 -1.414214\n",
            "1 -0.707107 -0.707107\n",
            "2  0.000000  0.000000\n",
            "3  0.707107  0.707107\n",
            "4  1.414214  1.414214\n"
          ]
        }
      ],
      "source": [
        "# Display the standardized DataFrame\n",
        "print(\"\\nDataFrame After Standardization (Z-score Scaling):\")\n",
        "print(df_standardized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eNsQVF8q8VK"
      },
      "source": [
        "# Part 8: Dropping Irrelevant Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "aKX8M1QUq-pN"
      },
      "outputs": [],
      "source": [
        "# Sample DataFrame with irrelevant columns\n",
        "data_with_irrelevant_columns = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'Salary': [50000, 60000, 70000]}\n",
        "df_irrelevant = pd.DataFrame(data_with_irrelevant_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvbIJkIArBYM",
        "outputId": "1f218c4e-ad8e-4ffc-fe0b-061af4ac5d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original DataFrame with Irrelevant Columns:\n",
            "      Name  Age  Salary\n",
            "0    Alice   25   50000\n",
            "1      Bob   30   60000\n",
            "2  Charlie   35   70000\n"
          ]
        }
      ],
      "source": [
        "# Display the original DataFrame\n",
        "print(\"\\nOriginal DataFrame with Irrelevant Columns:\")\n",
        "print(df_irrelevant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DStcO5INrDlf"
      },
      "outputs": [],
      "source": [
        "# Dropping the 'Salary' column\n",
        "df_cleaned = df_irrelevant.drop(columns=['Salary']) #specifying the column to be dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xf3FYhZrFsJ",
        "outputId": "61e5f372-cbf8-4b54-e099-3b200d759806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame After Dropping Irrelevant Columns:\n",
            "      Name  Age\n",
            "0    Alice   25\n",
            "1      Bob   30\n",
            "2  Charlie   35\n"
          ]
        }
      ],
      "source": [
        "# Display the cleaned DataFrame\n",
        "print(\"\\nDataFrame After Dropping Irrelevant Columns:\")\n",
        "print(df_cleaned)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
